{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Clustering.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vpWQigP0msj9"
      },
      "source": [
        "**Part 1:** \n",
        "\n",
        "Use the **Fashion-MNIST** dataset for this question.\n",
        "\n",
        "1) Load the dataset and perform splitting into training and validation sets with 70:30 ratio.\n",
        "\n",
        "> Do we need to normalise data? [If so Does it make any difference?]\n",
        "\n",
        "2) Implement the K Means algorithm. You need to find the optimal number of clusters using the\n",
        "    elbow method and silhouette method. \n",
        "\n",
        "3) Define the initial clustersâ€™ centroids using:</br>\n",
        "> i) Forgy</br>\n",
        "\n",
        "> ii) Random Partition\n",
        "\n",
        "4) Experiment with different distance measures[Euclidean distance, Manhattan distance].\n",
        "\n",
        "5) Plot the error vs number of clusters graph while using the elbow method and silhouette \n",
        "    method. Report the optimal number of clusters found.\n",
        "\n",
        "6) Report the training and the validation accuracy and Compare your trained model with a model trained by the scikit-learn\n",
        "\n",
        "7) Visualize the dataset to depict the clusters formed. #Prefer T-SNE\n",
        "\n",
        "8) Implement K-means++, and repeat task 1 to task 7 again.</br>\n",
        "</br>\n",
        "</br>\n",
        "</br>\n",
        "</br>\n",
        "**Part 2:**\n",
        "</br>\n",
        "In this task, you will perform operations on `[data.csv](https://drive.google.com/file/d/15NPkfXFoTkiRBlcI4ffe_Lp_BFOyf8UY/view?usp=sharing)`, data.csv is a  latent space representation of  Fashion-MNIST, before doing this task please read about latent space representation.\n",
        "\n",
        "9) Load the data.csv file and apply Kmeans and Kmeans++, You need to find the optimal number of clusters using the elbow method and silhouette method.\n",
        "\n",
        "10) Visualize the dataset to depict the clusters formed. # Prefer T-SNE\n",
        "\n",
        "11) From these experiments(Part 1 and Part 2), compare accuracy or error, and report which one is better and why?\n",
        "</br>\n",
        "</br>\n",
        "**Note:** If the model takes a lot of time to train you can use MiniBatchKMeans.\n",
        " \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yY8uMDe9quTE"
      },
      "source": [
        "#implement elbow method from scratch\n",
        "def elbow():\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "32x9M36qq2fO"
      },
      "source": [
        "#implement silhouette method from scratch\n",
        "def silhouette():\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AW0iiyC6qDlb"
      },
      "source": [
        "#implement Kmeans from scratch\n",
        "class Kmeans:\n",
        "\n",
        "  def __init__(self):\n",
        "\n",
        "\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h4dn0bULqg1I"
      },
      "source": [
        "#implement Kmeans++ from scratch\n",
        "class Kmeansplusplus:\n",
        "\n",
        "  def __init__(self):\n",
        "\n",
        "\n",
        " "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6j7nYmipmrC6"
      },
      "source": [
        "from keras.datasets import fashion_mnist\n",
        "(trainX, trainy), (testX, testy) = fashion_mnist.load_data()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}