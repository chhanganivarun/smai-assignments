{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "import torchvision\n",
    "from torchvision import transforms, datasets\n",
    "from torch import optim\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset= datasets.MNIST('~/.pytorch/MNIST/', train=True, download=True, transform=transform)\n",
    "\n",
    "validset= datasets.MNIST('~/.pytorch/MNIST/', train=True, download=True, transform=transform)\n",
    "\n",
    "testset= datasets.MNIST('~/.pytorch/MNIST/', train=False, download=True,transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "pin_memory = 1\n",
    "num_workers = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_train = len(trainset)\n",
    "num_test = len(testset)\n",
    "indices = list(range(num_train))\n",
    "split = int(np.floor(0.3 * num_train))\n",
    "\n",
    "np.random.seed(42)\n",
    "np.random.shuffle(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_idx, valid_idx = indices[split:], indices[:split]\n",
    "train_sampler = SubsetRandomSampler(train_idx)\n",
    "valid_sampler = SubsetRandomSampler(valid_idx)\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    trainset, batch_size=batch_size, sampler=train_sampler,\n",
    "    num_workers=num_workers, pin_memory=pin_memory,\n",
    ")\n",
    "valid_loader = torch.utils.data.DataLoader(\n",
    "    validset, batch_size=batch_size, sampler=valid_sampler,\n",
    "    num_workers=num_workers, pin_memory=pin_memory,\n",
    ")\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    testset, batch_size=batch_size, num_workers=num_workers, \n",
    "    pin_memory=pin_memory, shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 1, 28, 28]) torch.Size([100])\n"
     ]
    }
   ],
   "source": [
    "for imgs,labels in train_loader:\n",
    "    print(imgs.shape,labels.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPClassifier(nn.Module):\n",
    "    def __init__(self, hidden_channels=128):\n",
    "        super().__init__()\n",
    "        self.dense1 = nn.Linear(784,500)\n",
    "        self.dense2 = nn.Linear(500,100)\n",
    "        self.dense3 = nn.Linear(100,100)\n",
    "        self.dense4 = nn.Linear(100,10)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        out = x.view(x.shape[0],-1)\n",
    "        out = F.relu(self.dense1(out))\n",
    "        out = F.relu(self.dense2(out))\n",
    "        out = F.relu(self.dense3(out))\n",
    "        out = self.dense4(out)\n",
    "        \n",
    "        return out\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model):\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    for imgs,labels in valid_loader:\n",
    "        imgs = imgs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        preds = model(imgs)\n",
    "        outputs = torch.argmax(preds.data,1)\n",
    "\n",
    "        total += imgs.shape[0]\n",
    "\n",
    "        correct += 100.0*(outputs.cpu() == labels.cpu()).sum()\n",
    "    accuracy = correct/total\n",
    "    return accuracy.numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def XavierUniformInit(model):\n",
    "    if 'module' in model._modules.keys():\n",
    "        # in case of DataParallel\n",
    "        for key,val in model._modules['module']._modules.items():\n",
    "            if hasattr(val,'weight'):\n",
    "                try:\n",
    "                    nn.init.xavier_uniform_(val.weight.data)\n",
    "                    nn.init.zeros_(val.bias.data)\n",
    "                except:\n",
    "                    print('Couldn\\'t initialize for {}'.format(key))\n",
    "    else:\n",
    "        for key,val in model._modules.items():\n",
    "            if hasattr(val,'weight'):\n",
    "                try:\n",
    "                    nn.init.xavier_uniform_(val.weight.data)\n",
    "                    nn.init.zeros_(val.bias.data)\n",
    "                except:\n",
    "                    print('Couldn\\'t initialize for {}'.format(key))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def UniformInit(model):\n",
    "    if 'module' in model._modules.keys():\n",
    "        # in case of DataParallel\n",
    "        for key,val in model._modules['module']._modules.items():\n",
    "            if hasattr(val,'weight'):\n",
    "                try:\n",
    "                    nn.init.uniform_(val.weight.data)\n",
    "                    nn.init.zeros_(val.bias.data)\n",
    "                except:\n",
    "                    print('Couldn\\'t initialize for {}'.format(key))\n",
    "    else:\n",
    "        for key,val in model._modules.items():\n",
    "            if hasattr(val,'weight'):\n",
    "                try:\n",
    "                    nn.init.uniform_(val.weight.data)\n",
    "                    nn.init.zeros_(val.bias.data)\n",
    "                except:\n",
    "                    print('Couldn\\'t initialize for {}'.format(key))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NormalInit(model):\n",
    "    if 'module' in model._modules.keys():\n",
    "        # in case of DataParallel\n",
    "        for key,val in model._modules['module']._modules.items():\n",
    "            if hasattr(val,'weight'):\n",
    "                try:\n",
    "                    nn.init.normal_(val.weight.data)\n",
    "                    nn.init.zeros_(val.bias.data)\n",
    "                except:\n",
    "                    print('Couldn\\'t initialize for {}'.format(key))\n",
    "    else:\n",
    "        for key,val in model._modules.items():\n",
    "            if hasattr(val,'weight'):\n",
    "                try:\n",
    "                    nn.init.normal_(val.weight.data)\n",
    "                    nn.init.zeros_(val.bias.data)\n",
    "                except:\n",
    "                    print('Couldn\\'t initialize for {}'.format(key))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ZeroInit(model):\n",
    "    if 'module' in model._modules.keys():\n",
    "        # in case of DataParallel\n",
    "        for key,val in model._modules['module']._modules.items():\n",
    "            if hasattr(val,'weight'):\n",
    "                try:\n",
    "                    nn.init.normal_(val.weight.data)\n",
    "                    nn.init.zeros_(val.bias.data)\n",
    "                except:\n",
    "                    print('Couldn\\'t initialize for {}'.format(key))\n",
    "    else:\n",
    "        for key,val in model._modules.items():\n",
    "            if hasattr(val,'weight'):\n",
    "                try:\n",
    "                    nn.init.zeros_(val.weight.data)\n",
    "                    nn.init.zeros_(val.bias.data)\n",
    "                except:\n",
    "                    print('Couldn\\'t initialize for {}'.format(key))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DefaultInit(model):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25 of 25. Iteration: 420. Train Loss: 0.040975. Test Loss: 0.060895. Test Accuracy: 95.00\n",
      "Initialization: DefaultInit .Final Validation Accuracy: 97.28888702392578\n",
      "Epoch 25 of 25. Iteration: 420. Train Loss: 0.007937. Test Loss: 0.025502. Test Accuracy: 97.000\n",
      "Initialization: XavierUniformInit .Final Validation Accuracy: 97.55000305175781\n",
      "Epoch 25 of 25. Iteration: 420. Train Loss: 89.795143. Test Loss: 68.250000. Test Accuracy: 73.000000.00\n",
      "Initialization: UniformInit .Final Validation Accuracy: 67.22777557373047\n",
      "Epoch 25 of 25. Iteration: 420. Train Loss: 80.914796. Test Loss: 132.954391. Test Accuracy: 84.0000\n",
      "Initialization: NormalInit .Final Validation Accuracy: 88.69999694824219\n"
     ]
    }
   ],
   "source": [
    "for func in [DefaultInit,XavierUniformInit,UniformInit,NormalInit]:\n",
    "    model = MLPClassifier().to(device)\n",
    "    func(model)\n",
    "\n",
    "    lr = 1e-4\n",
    "    optimizer = optim.Adam(model.parameters(),lr= lr,weight_decay=1e-5)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    scheduler = optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.995)\n",
    "    epochs = 25\n",
    "    iter_n = 0\n",
    "    for e in range(epochs):\n",
    "        iter_n = 0\n",
    "        cumu_loss = 0\n",
    "    #     print(\"Epoch %d of %d\"%(e+1,epochs))\n",
    "        for imgs,labels in train_loader:\n",
    "\n",
    "            imgs = imgs.to(device)\n",
    "            labels = labels.to(device)\n",
    "    #         print(imgs.shape)\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            preds = model(imgs)\n",
    "            loss = criterion(preds,labels)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            cumu_loss += loss.item()\n",
    "\n",
    "            iter_n+=1\n",
    "    #         print(iter_n)\n",
    "            if iter_n % 420 == 0:\n",
    "                total = 0\n",
    "                correct = 0\n",
    "\n",
    "                for imgs,labels in valid_loader:\n",
    "                    imgs = imgs.to(device)\n",
    "                    labels = labels.to(device)\n",
    "\n",
    "                    preds = model(imgs)\n",
    "                    outputs = torch.argmax(preds.data,1)\n",
    "\n",
    "                    total += imgs.shape[0]\n",
    "\n",
    "                    correct += 100.0*(outputs.cpu() == labels.cpu()).sum()\n",
    "\n",
    "                    if total>= 50:\n",
    "                        break\n",
    "                accuracy = correct/total\n",
    "                print('\\rEpoch {} of {}. Iteration: {}. Train Loss: {:.6f}. Test Loss: {:.6f}. Test Accuracy: {:.2f}'.format(e+1, epochs, iter_n, cumu_loss/iter_n, loss.item(), accuracy), end='')\n",
    "        scheduler.step()\n",
    "\n",
    "    print('\\nInitialization: {} .Final Validation Accuracy: {}'.format(func.__name__,test(model)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 of 25. Iteration: 420. Train Loss: 0.341955. Test Loss: 0.341190. Test Accuracy: 91.00"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-59-9e04621028e4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mcumu_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;31m#     print(\"Epoch %d of %d\"%(e+1,epochs))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mimgs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0mimgs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimgs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/env/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/env/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    839\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    840\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 841\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    842\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    843\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/env/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    796\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    797\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_thread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_alive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 798\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    799\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    800\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/env/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    759\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    760\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 761\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    762\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    763\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/apps/python-3.7.4/lib/python3.7/queue.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    177\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mremaining\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnot_empty\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mremaining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    180\u001b[0m             \u001b[0mitem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnot_full\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnotify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/apps/python-3.7.4/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 300\u001b[0;31m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    301\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for func in [DefaultInit,XavierUniformInit,UniformInit,NormalInit]:\n",
    "    model = MLPClassifier().to(device)\n",
    "    func(model)\n",
    "\n",
    "    lr = 1e-4\n",
    "    optimizer = optim.RMSprop(model.parameters(),lr= lr,weight_decay=1e-5)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    scheduler = optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.995)\n",
    "    epochs = 25\n",
    "    iter_n = 0\n",
    "    for e in range(epochs):\n",
    "        iter_n = 0\n",
    "        cumu_loss = 0\n",
    "    #     print(\"Epoch %d of %d\"%(e+1,epochs))\n",
    "        for imgs,labels in train_loader:\n",
    "\n",
    "            imgs = imgs.to(device)\n",
    "            labels = labels.to(device)\n",
    "    #         print(imgs.shape)\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            preds = model(imgs)\n",
    "            loss = criterion(preds,labels)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            cumu_loss += loss.item()\n",
    "\n",
    "            iter_n+=1\n",
    "    #         print(iter_n)\n",
    "            if iter_n % 420 == 0:\n",
    "                total = 0\n",
    "                correct = 0\n",
    "\n",
    "                for imgs,labels in valid_loader:\n",
    "                    imgs = imgs.to(device)\n",
    "                    labels = labels.to(device)\n",
    "\n",
    "                    preds = model(imgs)\n",
    "                    outputs = torch.argmax(preds.data,1)\n",
    "\n",
    "                    total += imgs.shape[0]\n",
    "\n",
    "                    correct += 100.0*(outputs.cpu() == labels.cpu()).sum()\n",
    "\n",
    "                    if total>= 50:\n",
    "                        break\n",
    "                accuracy = correct/total\n",
    "                print('\\rEpoch {} of {}. Iteration: {}. Train Loss: {:.6f}. Test Loss: {:.6f}. Test Accuracy: {:.2f}'.format(e+1, epochs, iter_n, cumu_loss/iter_n, loss.item(), accuracy), end='')\n",
    "        scheduler.step()\n",
    "\n",
    "    print('\\nInitialization: {} .Final Validation Accuracy: {}'.format(func.__name__,test(model)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SGD with momentum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 of 25. Iteration: 420. Train Loss: 0.090023. Test Loss: 0.073090. Test Accuracy: 97.00"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-60-602ebe94fd6e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mcumu_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;31m#     print(\"Epoch %d of %d\"%(e+1,epochs))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mimgs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0mimgs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimgs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/env/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/env/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    839\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    840\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 841\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    842\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    843\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/env/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    796\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    797\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_thread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_alive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 798\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    799\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    800\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/env/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    759\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    760\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 761\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    762\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    763\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/apps/python-3.7.4/lib/python3.7/queue.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    177\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mremaining\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnot_empty\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mremaining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    180\u001b[0m             \u001b[0mitem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnot_full\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnotify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/apps/python-3.7.4/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 300\u001b[0;31m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    301\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for func in [DefaultInit,XavierUniformInit,UniformInit,NormalInit]:\n",
    "    model = MLPClassifier().to(device)\n",
    "    func(model)\n",
    "\n",
    "    lr = 0.1\n",
    "    optimizer = optim.SGD(model.parameters(),lr= lr,weight_decay=1e-5,momentum=0.7)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    scheduler = optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.995)\n",
    "    epochs = 25\n",
    "    iter_n = 0\n",
    "    for e in range(epochs):\n",
    "        iter_n = 0\n",
    "        cumu_loss = 0\n",
    "    #     print(\"Epoch %d of %d\"%(e+1,epochs))\n",
    "        for imgs,labels in train_loader:\n",
    "\n",
    "            imgs = imgs.to(device)\n",
    "            labels = labels.to(device)\n",
    "    #         print(imgs.shape)\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            preds = model(imgs)\n",
    "            loss = criterion(preds,labels)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            cumu_loss += loss.item()\n",
    "\n",
    "            iter_n+=1\n",
    "    #         print(iter_n)\n",
    "            if iter_n % 420 == 0:\n",
    "                total = 0\n",
    "                correct = 0\n",
    "\n",
    "                for imgs,labels in valid_loader:\n",
    "                    imgs = imgs.to(device)\n",
    "                    labels = labels.to(device)\n",
    "\n",
    "                    preds = model(imgs)\n",
    "                    outputs = torch.argmax(preds.data,1)\n",
    "\n",
    "                    total += imgs.shape[0]\n",
    "\n",
    "                    correct += 100.0*(outputs.cpu() == labels.cpu()).sum()\n",
    "\n",
    "                    if total>= 50:\n",
    "                        break\n",
    "                accuracy = correct/total\n",
    "                print('\\rEpoch {} of {}. Iteration: {}. Train Loss: {:.6f}. Test Loss: {:.6f}. Test Accuracy: {:.2f}'.format(e+1, epochs, iter_n, cumu_loss/iter_n, loss.item(), accuracy), end='')\n",
    "        scheduler.step()\n",
    "\n",
    "    print('\\nInitialization: {} .Final Validation Accuracy: {}'.format(func.__name__,test(model)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SGD without momentum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for func in [DefaultInit,XavierUniformInit,UniformInit,NormalInit]:\n",
    "    model = MLPClassifier().to(device)\n",
    "    func(model)\n",
    "\n",
    "    lr = 0.2\n",
    "    optimizer = optim.SGD(model.parameters(),lr= lr,weight_decay=1e-5)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    scheduler = optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.995)\n",
    "    epochs = 25\n",
    "    iter_n = 0\n",
    "    for e in range(epochs):\n",
    "        iter_n = 0\n",
    "        cumu_loss = 0\n",
    "    #     print(\"Epoch %d of %d\"%(e+1,epochs))\n",
    "        for imgs,labels in train_loader:\n",
    "\n",
    "            imgs = imgs.to(device)\n",
    "            labels = labels.to(device)\n",
    "    #         print(imgs.shape)\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            preds = model(imgs)\n",
    "            loss = criterion(preds,labels)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            cumu_loss += loss.item()\n",
    "\n",
    "            iter_n+=1\n",
    "    #         print(iter_n)\n",
    "            if iter_n % 420 == 0:\n",
    "                total = 0\n",
    "                correct = 0\n",
    "\n",
    "                for imgs,labels in valid_loader:\n",
    "                    imgs = imgs.to(device)\n",
    "                    labels = labels.to(device)\n",
    "\n",
    "                    preds = model(imgs)\n",
    "                    outputs = torch.argmax(preds.data,1)\n",
    "\n",
    "                    total += imgs.shape[0]\n",
    "\n",
    "                    correct += 100.0*(outputs.cpu() == labels.cpu()).sum()\n",
    "\n",
    "                    if total>= 50:\n",
    "                        break\n",
    "                accuracy = correct/total\n",
    "                print('\\rEpoch {} of {}. Iteration: {}. Train Loss: {:.6f}. Test Loss: {:.6f}. Test Accuracy: {:.2f}'.format(e+1, epochs, iter_n, cumu_loss/iter_n, loss.item(), accuracy), end='')\n",
    "        scheduler.step()\n",
    "\n",
    "    print('\\nInitialization: {} .Final Validation Accuracy: {}'.format(func.__name__,test(model)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutoEncoder(nn.Module):\n",
    "    def __init__(self, hidden_channels=128):\n",
    "        super().__init__()\n",
    "        self.cnn1 = nn.Conv2d(1,32,kernel_size=3,padding=1)\n",
    "        self.cnn2 = nn.Conv2d(32,64,kernel_size=3,padding=1)\n",
    "        self.cnn3 = nn.Conv2d(64,hidden_channels,kernel_size=7)\n",
    "\n",
    "        self.pool = nn.MaxPool2d(2,return_indices=True)\n",
    "        \n",
    "        self.unpool = nn.MaxUnpool2d(2)\n",
    "        \n",
    "        self.t_cnn1 = nn.ConvTranspose2d(hidden_channels,64,kernel_size=7)\n",
    "        self.t_cnn2 = nn.ConvTranspose2d(64,32,kernel_size=3,padding=1)\n",
    "        self.t_cnn3 = nn.ConvTranspose2d(32,1,kernel_size=3,padding=1)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        out = F.relu(self.cnn1(x))\n",
    "        out,ind1 = self.pool(out)\n",
    "        \n",
    "        out = F.relu(self.cnn2(out))\n",
    "        out,ind2 = self.pool(out)\n",
    "\n",
    "        out = self.cnn3(out)\n",
    "        \n",
    "        out = F.relu(self.t_cnn1(out))\n",
    "        out = self.unpool(out,ind2)\n",
    "\n",
    "        out = F.relu(self.t_cnn2(out))\n",
    "        out = self.unpool(out,ind1)\n",
    "\n",
    "        out = torch.sigmoid(self.t_cnn3(out))\n",
    "        \n",
    "        return out\n",
    "    def encoder(self,x):\n",
    "        out = F.relu(self.cnn1(x))\n",
    "        out,ind1 = self.pool(out)\n",
    "        \n",
    "        out = F.relu(self.cnn2(out))\n",
    "        out,ind2 = self.pool(out)\n",
    "\n",
    "        out = self.cnn3(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AutoEncoder(\n",
       "  (cnn1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (cnn2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (cnn3): Conv2d(64, 64, kernel_size=(7, 7), stride=(1, 1))\n",
       "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (unpool): MaxUnpool2d(kernel_size=(2, 2), stride=(2, 2), padding=(0, 0))\n",
       "  (t_cnn1): ConvTranspose2d(64, 64, kernel_size=(7, 7), stride=(1, 1))\n",
       "  (t_cnn2): ConvTranspose2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (t_cnn3): ConvTranspose2d(32, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       ")"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ae = AutoEncoder(hidden_channels=64).to(device)\n",
    "ae.load_state_dict(torch.load('q2.pth'))\n",
    "ae.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP_encoded(nn.Module):\n",
    "    def __init__(self,ae,hidden_channels=64):\n",
    "        super().__init__()\n",
    "        self.ae = ae\n",
    "        ae.eval()\n",
    "        self.dense1 = nn.Linear(64,32)\n",
    "        self.dense2 = nn.Linear(32,10)\n",
    "    def forward(self,x):\n",
    "        out = ae.encoder(x)\n",
    "        out = out.view(out.shape[0],-1)\n",
    "        out = F.relu(self.dense1(out))\n",
    "        out = self.dense2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MLP_encoded(ae,hidden_channels=64).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25 of 25. Iteration: 420. Train Loss: 0.034926. Test Loss: 0.034584. Test Accuracy: 97.000Final Validation Accuracy: 98.2388916015625\n"
     ]
    }
   ],
   "source": [
    "\n",
    "lr = 1e-4\n",
    "optimizer = optim.RMSprop(model.parameters(),lr= lr,weight_decay=1e-5)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "scheduler = optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.995)\n",
    "epochs = 25\n",
    "iter_n = 0\n",
    "for e in range(epochs):\n",
    "    iter_n = 0\n",
    "    cumu_loss = 0\n",
    "#     print(\"Epoch %d of %d\"%(e+1,epochs))\n",
    "    for imgs,labels in train_loader:\n",
    "\n",
    "        imgs = imgs.to(device)\n",
    "        labels = labels.to(device)\n",
    "#         print(imgs.shape)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        preds = model(imgs)\n",
    "        loss = criterion(preds,labels)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        cumu_loss += loss.item()\n",
    "\n",
    "        iter_n+=1\n",
    "#         print(iter_n)\n",
    "        if iter_n % 420 == 0:\n",
    "            total = 0\n",
    "            correct = 0\n",
    "\n",
    "            for imgs,labels in valid_loader:\n",
    "                imgs = imgs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                preds = model(imgs)\n",
    "                outputs = torch.argmax(preds.data,1)\n",
    "\n",
    "                total += imgs.shape[0]\n",
    "\n",
    "                correct += 100.0*(outputs.cpu() == labels.cpu()).sum()\n",
    "\n",
    "                if total>= 50:\n",
    "                    break\n",
    "            accuracy = correct/total\n",
    "            print('\\rEpoch {} of {}. Iteration: {}. Train Loss: {:.6f}. Test Loss: {:.6f}. Test Accuracy: {:.2f}'.format(e+1, epochs, iter_n, cumu_loss/iter_n, loss.item(), accuracy), end='')\n",
    "    scheduler.step()\n",
    "\n",
    "print('\\nFinal Validation Accuracy: {}'.format(test(model)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
